services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.7.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"

  broker:
    image: confluentinc/cp-kafka:7.7.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_INTERNAL://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://broker:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_LOG_RETENTION_MS: 60000 # 1 minute - this will always trigger before log.retention.bytes.
      KAFKA_LOG_RETENTION_BYTES: 1073741824 # 1GB per partition, if exceeding this or log.retention.ms, the log will be deleted.
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000 # 5 minutes - check interval for log retention. This is default.
      KAFKA_DELETE_RETENTION_MS: 600000 # 10 minutes - cleanup window
      KAFKA_LOG_SEGMENT_BYTES: 41824 # 40.8kB per segment - closes segmentwhen exceeding this
      KAFKA_LOG_SEGMENT_JITTER_MS: 10000 # 10 seconds

  kafdrop:
    image: obsidiandynamics/kafdrop:4.0.2
    container_name: kafdrop
    depends_on:
      - broker
    environment:
      KAFKA_BROKERCONNECT: "kafka:9092"
    ports:
      - "9000:9000"

volumes:
  kafka_data: